#!/usr/bin/env python3
"""
Test-Script fÃ¼r Aldi-Crawler mit direkter Suchfunktion

Dieses Script testet die vollstÃ¤ndige FunktionalitÃ¤t des optimierten Aldi-Crawlers
mit direkter Nutzung der Aldi-Suchfunktion und gibt detaillierte Informationen 
Ã¼ber Performance und Ergebnisse aus.

Verwendung:
    python test_aldi_crawler.py
"""

import asyncio
import time
import sys
import os
from decimal import Decimal
from typing import List

# Pfad fÃ¼r Importe hinzufÃ¼gen
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.core.config import settings
from app.services.aldi_crawler import create_aldi_crawler
from app.models.search import ProductResult

def print_header():
    """Druckt einen schÃ¶nen Header"""
    print("ğŸ”¥" + "="*60)
    print("ğŸ”¥ Teste Aldi-Crawler mit direkter Suchfunktion")
    print("ğŸ”¥ Nutzt: https://www.aldi-sued.de/de/suchergebnis.html")
    print("ğŸ”¥" + "="*60)
    print()

def print_config_status():
    """ÃœberprÃ¼ft und zeigt die aktuelle Konfiguration an"""
    print("âš™ï¸  Konfiguration:")
    print(f"   - Environment: {settings.app_env}")
    print(f"   - Firecrawl aktiviert: {settings.firecrawl_enabled}")
    
    if settings.firecrawl_api_key:
        # API-Key maskiert anzeigen
        key = settings.firecrawl_api_key
        masked_key = f"{key[:8]}{'*' * (len(key) - 12)}{key[-4:]}" if len(key) > 12 else "fc-****...****"
        print(f"   - API Key verfÃ¼gbar: {masked_key}")
    else:
        print("   - âŒ API Key fehlt!")
    
    print(f"   - Aldi-Crawler: {settings.aldi_crawler_enabled}")
    print(f"   - Cache-Zeit: {settings.firecrawl_max_age/1000/60:.1f} Minuten")
    print(f"   - Max. Ergebnisse: {settings.firecrawl_max_results_per_store}")
    print(f"   - Aldi Such-URL: {settings.aldi_base_url}/de/suchergebnis.html")
    print()

async def test_product_search(crawler, query: str, test_name: str = None):
    """Testet eine Produktsuche und zeigt Ergebnisse an"""
    if not test_name:
        test_name = f"Produktsuche: '{query}'"
    
    print(f"ğŸ›’ Teste {test_name}")
    print(f"   ğŸ” Such-URL: https://www.aldi-sued.de/de/suchergebnis.html?search={query}")
    
    start_time = time.time()
    try:
        results = await crawler.search_products(query=query, max_results=10)
        end_time = time.time()
        
        duration = end_time - start_time
        print(f"   â±ï¸  Suchzeit: {duration:.1f}s")
        print(f"   ğŸ“Š Gefunden: {len(results)} Produkte")
        
        if results:
            # Preisbereich anzeigen
            prices = [float(p.price) for p in results]
            min_price = min(prices)
            max_price = max(prices)
            avg_price = sum(prices) / len(prices)
            print(f"   ğŸ’° Preise: â‚¬{min_price:.2f} - â‚¬{max_price:.2f} (Ã˜ â‚¬{avg_price:.2f})")
            
            # Erste 3 Produkte detailliert anzeigen
            print("   ğŸ“‹ Top-Ergebnisse:")
            for i, product in enumerate(results[:3]):
                brand_info = f" ({product.brand})" if product.brand else ""
                unit_info = f" | {product.unit}" if product.unit else ""
                category_info = f" | {product.category}" if product.category else ""
                
                print(f"      {i+1}. {product.name}{brand_info}")
                print(f"         ğŸ’° â‚¬{product.price}{unit_info}{category_info}")
                
                if product.origin:
                    print(f"         ğŸŒ Herkunft: {product.origin}")
                if product.quality_info:
                    print(f"         â­ QualitÃ¤t: {product.quality_info}")
                if product.discount:
                    print(f"         ğŸ¯ Aktion: {product.discount}")
                print()
        else:
            print("   âŒ Keine Produkte gefunden")
            
    except Exception as e:
        print(f"   âŒ Fehler: {e}")
        import traceback
        print(f"   ğŸ“‹ Details: {traceback.format_exc()}")
    
    print()

def test_price_parsing():
    """Testet die Preisverarbeitung mit verschiedenen deutschen Formaten"""
    print("ğŸ’° Teste deutsche Preisverarbeitung:")
    
    # Import der parse_price Methode fÃ¼r direkten Test
    from app.services.aldi_crawler import AldiCrawler
    crawler = AldiCrawler()
    
    test_prices = [
        # Aldi-typische Formate
        ("â‚¬ 1,79", 1.79),
        ("â‚¬ 2,55", 2.55),
        ("â‚¬ 1,35", 1.35),
        ("2,19", 2.19),
        ("1,85", 1.85),
        
        # Verschiedene deutsche Formate
        ("â‚¬ 12,99*", 12.99),
        ("4,99 â‚¬", 4.99),
        ("â‚¬2,50", 2.50),
        ("1.234,56", 1234.56),  # Tausender-Format
        ("0,89", 0.89),
        
        # Edge Cases
        ("invalid", None),
        ("", None),
        ("â‚¬ 0,00", None),  # Sollte als ungÃ¼ltig erkannt werden
        ("â‚¬ 1000", None),  # Ãœber dem erwarteten Limit
        ("â‚¬ -1,50", None)  # Negative Preise
    ]
    
    success_count = 0
    total_count = len(test_prices)
    
    for price_str, expected in test_prices:
        result = crawler._parse_price(price_str)
        
        # Exaktere Vergleichslogik fÃ¼r Decimal
        if expected is None:
            success = result is None
        else:
            success = result is not None and abs(float(result) - expected) < 0.001
        
        if success:
            success_count += 1
            
        status = "âœ…" if success else "âŒ"
        result_str = f"â‚¬{result}" if result else "None"
        expected_str = f"â‚¬{expected}" if expected else "None"
        print(f"   {status} '{price_str}' â†’ {result_str} (erwartet: {expected_str})")
    
    print(f"   ğŸ“Š Erfolgsrate: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
    print()

def analyze_results(results: List[ProductResult], query: str):
    """Analysiert die Suchergebnisse und zeigt Statistiken"""
    if not results:
        return
    
    print(f"ğŸ“Š Detailanalyse fÃ¼r '{query}' ({len(results)} Produkte):")
    
    # Kategorien, Marken, Einheiten sammeln
    categories = {}
    brands = {}
    units = {}
    price_ranges = {"0-2â‚¬": 0, "2-5â‚¬": 0, "5-10â‚¬": 0, "10â‚¬+": 0}
    
    for product in results:
        # Kategorien
        if product.category:
            categories[product.category] = categories.get(product.category, 0) + 1
        
        # Marken
        if product.brand:
            brands[product.brand] = brands.get(product.brand, 0) + 1
        
        # Einheiten
        if product.unit:
            # Vereinfache Einheiten (entferne Grundpreise)
            unit = product.unit.split('(')[0].strip() if '(' in product.unit else product.unit
            units[unit] = units.get(unit, 0) + 1
        
        # Preisverteilung
        price = float(product.price)
        if price < 2:
            price_ranges["0-2â‚¬"] += 1
        elif price < 5:
            price_ranges["2-5â‚¬"] += 1
        elif price < 10:
            price_ranges["5-10â‚¬"] += 1
        else:
            price_ranges["10â‚¬+"] += 1
    
    # Top 5 anzeigen
    if categories:
        print("   ğŸ“‚ Top Kategorien:")
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"      - {category}: {count}")
    
    if brands:
        print("   ğŸ·ï¸  Top Marken:")
        for brand, count in sorted(brands.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"      - {brand}: {count}")
    
    if units:
        print("   ğŸ“¦ Top Einheiten:")
        for unit, count in sorted(units.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"      - {unit}: {count}")
    
    print("   ğŸ’° Preisverteilung:")
    for range_name, count in price_ranges.items():
        percentage = count / len(results) * 100 if results else 0
        print(f"      - {range_name}: {count} ({percentage:.1f}%)")
    
    print()

def test_search_url_generation():
    """Testet die URL-Generierung fÃ¼r verschiedene Suchbegriffe"""
    print("ğŸ”— Teste Such-URL Generierung:")
    
    from app.services.aldi_crawler import AldiCrawler
    import urllib.parse
    
    test_queries = [
        "Milch",
        "Oatly",
        "Bio Brot",
        "Apfel & Birne",
        "MÃ¼ller Milch",
        "100% natÃ¼rlich",
        "test with spaces",
        "Umlaut: MÃ¼sli"
    ]
    
    base_url = settings.aldi_base_url + "/de/suchergebnis.html"
    
    for query in test_queries:
        encoded_query = urllib.parse.quote_plus(query)
        expected_url = f"{base_url}?search={encoded_query}"
        print(f"   âœ… '{query}' â†’ {expected_url}")
    
    print()

async def test_edge_cases(crawler):
    """Testet Edge Cases und FehlerzustÃ¤nde"""
    print("ğŸ§ª Teste Edge Cases:")
    
    edge_cases = [
        ("", "Leerer Suchbegriff"),
        ("x", "Sehr kurzer Begriff (1 Zeichen)"),
        ("abcdefghijklmnopqrstuvwxyz1234567890", "Sehr langer Begriff"),
        ("!!!@@@###", "Sonderzeichen"),
        ("NonExistentProductBrand123XYZ", "Nicht existierendes Produkt")
    ]
    
    for query, description in edge_cases:
        print(f"   ğŸ” {description}: '{query}'")
        try:
            start_time = time.time()
            results = await crawler.search_products(query=query, max_results=5)
            duration = time.time() - start_time
            print(f"      â±ï¸  {duration:.1f}s | ğŸ“Š {len(results)} Ergebnisse")
        except Exception as e:
            print(f"      âŒ Fehler: {e}")
    
    print()

async def run_comprehensive_tests():
    """FÃ¼hrt umfassende Tests des optimierten Crawlers durch"""
    print_header()
    print_config_status()
    
    # Konfiguration validieren
    if not settings.firecrawl_enabled:
        print("âŒ Firecrawl ist deaktiviert. Bitte setze FIRECRAWL_ENABLED=true in .env")
        return
    
    if not settings.firecrawl_api_key:
        print("âŒ Firecrawl API Key fehlt. Bitte setze FIRECRAWL_API_KEY in .env")
        return
    
    # Crawler initialisieren
    print("ğŸš€ Initialisiere optimierten Aldi-Crawler...")
    crawler = create_aldi_crawler()
    
    if not crawler:
        print("âŒ Crawler konnte nicht initialisiert werden!")
        return
    
    print("âœ… Crawler erfolgreich initialisiert!")
    print()
    
    # URL-Generierung testen
    test_search_url_generation()
    
    # Preisverarbeitung testen
    test_price_parsing()
    
    # Test-Queries fÃ¼r echte Aldi-Suche
    test_queries = [
        ("Oatly", "Spezifische Marke"),
        ("Milch", "HÃ¤ufiges Grundprodukt"),
        ("Bio", "Bio-Produkte"),
        ("Brot", "Backwaren"),
        ("KÃ¤se", "Molkereiprodukte"),
        ("Apfel", "Obst"),
        ("Nudeln", "Teigwaren"),
        ("Schokolade", "SÃ¼ÃŸwaren")
    ]
    
    # Alle Tests durchfÃ¼hren
    all_results = {}
    total_search_time = 0
    
    print("ğŸ” Starte Produktsuche-Tests:")
    print()
    
    for query, description in test_queries:
        start_time = time.time()
        await test_product_search(crawler, query, description)
        search_time = time.time() - start_time
        total_search_time += search_time
        
        # ZusÃ¤tzliche Analyse fÃ¼r erfolgreiche Suchen
        try:
            results = await crawler.search_products(query=query, max_results=10)
            if results:
                all_results[query] = results
                analyze_results(results, query)
        except Exception as e:
            print(f"   âŒ Analyse-Fehler fÃ¼r '{query}': {e}")
    
    # Edge Cases testen
    await test_edge_cases(crawler)
    
    # Gesamtstatistik
    print("ğŸ“ˆ Gesamtstatistik:")
    total_tests = len(test_queries)
    successful_tests = len(all_results)
    success_rate = successful_tests/total_tests*100 if total_tests > 0 else 0
    
    print(f"   - Tests durchgefÃ¼hrt: {total_tests}")
    print(f"   - Erfolgreiche Suchen: {successful_tests}")
    print(f"   - Erfolgsrate: {success_rate:.1f}%")
    print(f"   - Gesamtsuchzeit: {total_search_time:.1f}s")
    
    if successful_tests > 0:
        avg_search_time = total_search_time / total_tests
        print(f"   - Durchschnittliche Suchzeit: {avg_search_time:.1f}s")
    
    total_products = sum(len(results) for results in all_results.values())
    print(f"   - Gesamt gefundene Produkte: {total_products}")
    
    if all_results:
        avg_products = total_products / len(all_results)
        print(f"   - Durchschnitt pro Suche: {avg_products:.1f}")
    
    # Performance-Bewertung
    print()
    print("âš¡ Performance-Bewertung:")
    if successful_tests == total_tests:
        print("   âœ… Ausgezeichnet: Alle Tests erfolgreich!")
    elif success_rate >= 80:
        print("   âœ… Gut: Hohe Erfolgsrate")
    elif success_rate >= 60:
        print("   âš ï¸  MittelmÃ¤ÃŸig: Einige Tests fehlgeschlagen")
    else:
        print("   âŒ Schlecht: Viele Tests fehlgeschlagen")
    
    if total_search_time / total_tests < 5:
        print("   âœ… Schnell: Gute Response-Zeiten")
    elif total_search_time / total_tests < 10:
        print("   âš ï¸  Langsam: Moderate Response-Zeiten")
    else:
        print("   âŒ Sehr langsam: Hohe Response-Zeiten")
    
    print()
    print("âœ… Alle Tests abgeschlossen!")

def check_environment():
    """ÃœberprÃ¼ft die Umgebungsvariablen und Environment-Setup"""
    print("ğŸ” ÃœberprÃ¼fe Multi-Environment Setup:")
    
    # Aktuelle Environment anzeigen
    current_env = settings.app_env
    print(f"   ğŸ“ Aktuelle Umgebung: {current_env}")
    
    # Entsprechende .env-Datei suchen
    env_file = f".env.{current_env}"
    if os.path.exists(env_file):
        print(f"   âœ… Environment-Datei gefunden: {env_file}")
        
        # .env-Datei lesen und relevante Variablen anzeigen
        with open(env_file, 'r') as f:
            lines = f.readlines()
        
        relevant_vars = ['FIRECRAWL_API_KEY', 'FIRECRAWL_ENABLED', 'ALDI_CRAWLER_ENABLED', 'ALDI_BASE_URL']
        found_vars = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#'):
                for var in relevant_vars:
                    if line.startswith(f"{var}="):
                        found_vars.append(var)
                        value = line.split('=', 1)[1]
                        if var == 'FIRECRAWL_API_KEY' and value:
                            # API Key maskieren
                            if len(value) > 8:
                                value = f"{value[:4]}...{value[-4:]}"
                        print(f"   âœ… {var}={value}")
        
        missing_vars = set(relevant_vars) - set(found_vars)
        for var in missing_vars:
            print(f"   âŒ {var} nicht gefunden")
    else:
        print(f"   âŒ Environment-Datei nicht gefunden: {env_file}")
        print(f"   ğŸ’¡ Erstelle {env_file} mit:")
        print(f"      FIRECRAWL_API_KEY=fc-your-key-here")
        print(f"      FIRECRAWL_ENABLED=true")
        print(f"      ALDI_CRAWLER_ENABLED=true")
        print(f"      ALDI_BASE_URL=https://www.aldi-sued.de")
    
    # Alternative .env-Dateien anzeigen
    env_files = [f for f in os.listdir('.') if f.startswith('.env')]
    if env_files:
        print(f"   ğŸ“„ VerfÃ¼gbare Environment-Dateien: {', '.join(env_files)}")
    
    print()

if __name__ == "__main__":
    print("ğŸ”§ Aldi-Crawler Test Suite v2.0")
    print("ğŸ¯ Optimiert fÃ¼r direkte Aldi-Suchfunktion")
    print("=" * 50)
    print()
    
    # Umgebung Ã¼berprÃ¼fen
    check_environment()
    
    # Haupttests ausfÃ¼hren
    try:
        asyncio.run(run_comprehensive_tests())
    except KeyboardInterrupt:
        print("\nğŸ›‘ Tests durch Benutzer abgebrochen")
    except Exception as e:
        print(f"\nâŒ Unerwarteter Fehler: {e}")
        import traceback
        traceback.print_exc() 