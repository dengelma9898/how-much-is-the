# Availability & Cleanup System Documentation

## Ãœbersicht

Das erweiterte System verwaltet jetzt ProduktverfÃ¼gbarkeit und Angebots-Enddaten intelligent, um eine automatische Datenbereinigung zu ermÃ¶glichen.

## ğŸ”„ Neue Felder

### ProductResult Model (API)
```python
availability: bool = Field(default=True, description="VerfÃ¼gbarkeitsstatus im Store")
availability_text: Optional[str] = Field(None, description="VerfÃ¼gbarkeitstext vom Store")
offer_valid_until: Optional[str] = Field(None, description="Bis wann das Angebot gÃ¼ltig ist")
```

### DatabaseProduct Model (Datenbank)
```sql
availability_text VARCHAR(255)    -- Original-Text vom Store
offer_valid_until VARCHAR(10)     -- YYYY-MM-DD Format
```

## ğŸ“… VerfÃ¼gbarkeits-Parsing

### UnterstÃ¼tzte Textformate

Das System erkennt automatisch VerfÃ¼gbarkeits- und Datumsinformationen:

```
"nur in der Filiale 07.07. - 12.07."      â†’ available=true, until=2026-07-12
"nur online 15.01. - 20.01."               â†’ available=true, until=2026-01-20
"VerfÃ¼gbar bis 31.12.2024"                 â†’ available=true, until=2024-12-31
"ausverkauft"                               â†’ available=false, until=null
"nicht verfÃ¼gbar"                           â†’ available=false, until=null
"vergriffen"                                â†’ available=false, until=null
"Angebot gÃ¼ltig 05.03. - 10.03."          â†’ available=true, until=2026-03-10
```

### Smart Datumslogik

- **Ohne Jahr**: Aktuelles Jahr oder nÃ¤chstes Jahr (falls >30 Tage in Vergangenheit)
- **Mit Jahr**: Direktes Parsing
- **Vergangene Daten**: Automatisch `availability=false`
- **Mehrere Daten**: SpÃ¤testes Datum wird verwendet

## ğŸ§¹ Cleanup System

### Cleanup Service Funktionen

#### 1. Abgelaufene Angebote bereinigen
```python
await cleanup_service.cleanup_expired_offers(dry_run=True)
```

**Funktionsweise:**
- Findet Produkte mit `offer_valid_until < heute`
- Markiert als `deleted_at = jetzt` und `availability = false` (Soft Delete)
- Liefert detaillierte Statistiken

#### 2. Alte Produkte bereinigen
```python
await cleanup_service.cleanup_old_products(days_old=30, dry_run=True)
```

**Funktionsweise:**
- Findet Produkte Ã¤lter als X Tage ohne Enddatum
- Bereinigt "verwaiste" Daten ohne Angebotszeitraum
- Ideal fÃ¼r regelmÃ¤ÃŸige Maintenance

#### 3. Cleanup-Statistiken
```python
await cleanup_service.get_cleanup_statistics()
```

**Liefert:**
- Anzahl aktiver Produkte
- Produkte mit/ohne Enddatum
- Abgelaufene Angebote
- Bald ablaufende Angebote (7 Tage)
- Coverage-Prozentsatz

## ğŸŒ Admin API Endpoints

### Cleanup-Statistiken abrufen
```http
GET /api/v1/admin/cleanup/statistics
```

**Response:**
```json
{
  "analysis_date": "2025-07-10",
  "total_active_products": 150,
  "products_with_end_date": 75,
  "products_without_end_date": 75,
  "expired_offers": 12,
  "expiring_soon_offers": 8,
  "deleted_products": 35,
  "cleanup_recommendations": {
    "immediate_cleanup_candidates": 12,
    "requires_attention": 8,
    "coverage": "50.0%"
  }
}
```

### Abgelaufene Angebote bereinigen
```http
POST /api/v1/admin/cleanup/expired?dry_run=true&triggered_by=admin
```

**Dry Run Response:**
```json
{
  "analysis_date": "2025-07-10",
  "total_expired_found": 12,
  "expired_by_store": {
    "LIDL": 8,
    "Aldi SÃ¼d": 4
  },
  "expired_products": [
    {
      "id": 123,
      "name": "Bio Vollmilch",
      "store": "LIDL",
      "price": 1.59,
      "offer_valid_until": "2025-07-05",
      "availability_text": "nur in der Filiale 05.07. - 10.07.",
      "created_at": "2025-07-01T10:00:00"
    }
  ],
  "action_taken": "dry_run",
  "triggered_by": "admin",
  "note": "This was a dry run - no data was deleted"
}
```

### Alte Produkte bereinigen
```http
POST /api/v1/admin/cleanup/old-products?days_old=30&dry_run=false&triggered_by=admin
```

**Real Cleanup Response:**
```json
{
  "cutoff_date": "2025-06-10T00:00:00",
  "days_old_threshold": 30,
  "total_old_found": 25,
  "old_by_store": {
    "LIDL": 15,
    "Aldi SÃ¼d": 10
  },
  "action_taken": "deleted",
  "deleted_count": 25,
  "cleanup_id": "cleanup_old_1720602000",
  "triggered_by": "admin"
}
```

## ğŸ”§ Integration mit bestehenden Systemen

### Lidl Crawler Integration

Der Lidl Crawler verwendet automatisch die neue Parsing-Logik:

```python
# In lidl_crawler_ultimate.py
availability, parsed_availability_text, offer_valid_until = self._parse_availability_and_date(availability_text)

product = ProductResult(
    name=name,
    price=price,
    store="LIDL",
    availability=availability,
    availability_text=parsed_availability_text,
    offer_valid_until=offer_valid_until,
    # ... andere Felder
)
```

### Datenbank-Migration

```sql
-- Neue Felder hinzugefÃ¼gt
ALTER TABLE products ADD COLUMN availability_text VARCHAR(255);
ALTER TABLE products ADD COLUMN offer_valid_until VARCHAR(10);

-- Index fÃ¼r Performance
CREATE INDEX idx_products_offer_valid_until ON products(offer_valid_until);
```

## ğŸ“Š Monitoring & Wartung

### Empfohlene Cleanup-Routine

1. **TÃ¤glich**: Cleanup-Statistiken prÃ¼fen
   ```bash
   curl "http://localhost:8000/api/v1/admin/cleanup/statistics"
   ```

2. **TÃ¤glich**: Abgelaufene Angebote bereinigen
   ```bash
   curl -X POST "http://localhost:8000/api/v1/admin/cleanup/expired?dry_run=false"
   ```

3. **WÃ¶chentlich**: Alte Produkte bereinigen (30+ Tage)
   ```bash
   curl -X POST "http://localhost:8000/api/v1/admin/cleanup/old-products?days_old=30&dry_run=false"
   ```

### Performance-Optimierungen

- **Indizierte Felder**: `offer_valid_until`, `deleted_at`, `created_at`
- **Soft Deletes**: Keine harten LÃ¶schungen fÃ¼r Audit-Trail
- **Batch Processing**: Cleanup lÃ¤uft als Background-Tasks
- **Rate Limiting**: Schutz vor Ã¼bermÃ¤ÃŸiger Bereinigung

## ğŸ§ª Testing

### VerfÃ¼gbarkeits-Parsing testen
```bash
cd backend
arch -arm64 python3 test_lidl_availability_parsing.py
```

**Test-Abdeckung:**
- 12 verschiedene VerfÃ¼gbarkeitstext-Formate
- Datumsvalidierung (Vergangenheit/Zukunft)
- ProductResult-Erstellung mit neuen Feldern
- Echte Lidl-Crawler-Integration

### API-Tests
```bash
# Cleanup-Statistiken
curl "http://localhost:8000/api/v1/admin/cleanup/statistics"

# Dry Run Test
curl -X POST "http://localhost:8000/api/v1/admin/cleanup/expired?dry_run=true"

# Real Cleanup Test
curl -X POST "http://localhost:8000/api/v1/admin/cleanup/expired?dry_run=false"
```

## ğŸš€ Vorteile der neuen Architektur

### 1. Intelligente Datenbereinigung
- **Automatisch**: Abgelaufene Angebote werden erkannt
- **Datenbasiert**: Verwendung echter Store-Informationen
- **Flexibel**: Verschiedene Bereinigungsstrategien

### 2. Verbesserte DatenqualitÃ¤t
- **AktualitÃ¤t**: Nur gÃ¼ltige Angebote in Suchergebnissen
- **Transparenz**: Original-VerfÃ¼gbarkeitstext verfÃ¼gbar
- **Nachverfolgbarkeit**: Soft Deletes mit Timestamps

### 3. Admin-Freundlichkeit
- **Dry Run**: Sichere Analyse vor tatsÃ¤chlicher Bereinigung
- **Statistiken**: Detaillierte Einblicke in Datenbestand
- **Background Processing**: Keine Blockierung der API

### 4. Store-spezifische Anpassung
- **Lidl-optimiert**: Spezielle Parsing-Logik fÃ¼r Lidl-Texte
- **Erweiterbar**: Aldi und andere Stores spÃ¤ter hinzufÃ¼gbar
- **Robust**: Fallback-Verhalten bei unbekannten Formaten

## ğŸ”® Zukunftige Erweiterungen

### 1. Automatische Cleanup-Scheduler
```python
# In scheduler_service.py
@scheduler.scheduled_job('cron', hour=2)  # TÃ¤glich um 2 Uhr
async def auto_cleanup_expired():
    await cleanup_service.cleanup_expired_offers(dry_run=False)
```

### 2. Warehouse-Integration
- LagerverfÃ¼gbarkeit in Echtzeit
- Store-spezifische VerfÃ¼gbarkeit
- Filial-lokale Angebote

### 3. ML-basierte Preisprognose
- Verwendung historischer Angebotsdaten
- Vorhersage von PreisÃ¤nderungen
- Optimale Einkaufszeitpunkte

### 4. Push-Benachrichtigungen
- Benachrichtigung bei bald ablaufenden Angeboten
- Preisalerts fÃ¼r Lieblings-Produkte
- Admin-Alerts bei Cleanup-Anomalien

## ğŸ“‹ Checkliste fÃ¼r Deployment

- [ ] Datenbank-Migration ausgefÃ¼hrt (`add_availability_fields.py`)
- [ ] Lidl Crawler mit neuen Feldern getestet
- [ ] Cleanup Service FunktionalitÃ¤t validiert
- [ ] Admin API Endpoints getestet
- [ ] Monitoring/Logging konfiguriert
- [ ] Backup-Strategie aktualisiert
- [ ] Dokumentation fÃ¼r Ops-Team bereitgestellt

## ğŸ’¡ Best Practices

1. **Immer mit Dry Run beginnen** vor echten Cleanup-Operationen
2. **RegelmÃ¤ÃŸige Backup-Erstellung** vor grÃ¶ÃŸeren Bereinigungen
3. **Monitoring der Cleanup-Statistiken** fÃ¼r ungewÃ¶hnliche Muster
4. **Stufenweise Ausrollung** bei Produktionsumgebungen
5. **Audit-Logs** fÃ¼r alle Cleanup-Operationen fÃ¼hren 