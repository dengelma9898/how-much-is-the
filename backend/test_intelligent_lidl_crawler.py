"""
Test-Skript f√ºr den intelligenten Lidl-Crawler mit BeautifulSoup + LLM-Integration
"""

import asyncio
import logging
import sys
import os
from pprint import pprint

# Pfad zum app-Ordner hinzuf√ºgen
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from app.services.lidl_crawler_bs4 import create_intelligent_lidl_crawler

# Logging konfigurieren
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_intelligent_lidl_crawler():
    """Testet den intelligenten Lidl-Crawler"""
    try:
        logger.info("üß† Starte Test f√ºr intelligenten Lidl-Crawler...")
        
        # Intelligenten Lidl-Crawler erstellen
        crawler = create_intelligent_lidl_crawler()
        
        if not crawler:
            logger.error("‚ùå Intelligenter Lidl-Crawler konnte nicht initialisiert werden")
            return
        
        logger.info("‚úÖ Intelligenter Lidl-Crawler erfolgreich initialisiert")
        
        # Async context manager verwenden
        async with crawler:
            # Test-Queries
            test_queries = [
                "milch",
                "brot", 
                "k√§se",
                "apfel",
                "fleisch"
            ]
            
            for query in test_queries:
                logger.info(f"\nüîç Teste Query: '{query}'")
                try:
                    results = await crawler.search_products(query, max_results=5)
                    
                    if results:
                        logger.info(f"üéØ Gefunden: {len(results)} Produkte f√ºr '{query}'")
                        for i, product in enumerate(results, 1):
                            logger.info(f"  {i}. {product.name} - ‚Ç¨{product.price} ({product.store})")
                            if product.unit:
                                logger.info(f"     Einheit: {product.unit}")
                            if product.brand:
                                logger.info(f"     Marke: {product.brand}")
                            if product.available_until:
                                logger.info(f"     Verf√ºgbar: {product.available_until}")
                    else:
                        logger.info(f"üìä Keine Produkte f√ºr '{query}' gefunden")
                        
                except Exception as e:
                    logger.error(f"‚ùå Fehler bei Query '{query}': {e}")
                
                # Kurze Pause zwischen Requests
                await asyncio.sleep(1)
        
        logger.info("üéâ Intelligenter Lidl-Crawler Test abgeschlossen!")
        
    except Exception as e:
        logger.error(f"‚ùå Fehler beim Test: {e}", exc_info=True)

async def test_raw_extraction():
    """Testet nur die rohe HTML-Extraktion ohne LLM"""
    try:
        logger.info("\nüîß Teste rohe HTML-Extraktion...")
        
        crawler = create_intelligent_lidl_crawler()
        if not crawler:
            return
        
        async with crawler:
            # HTML-Inhalt laden
            html_content = await crawler._fetch_page_content()
            if html_content:
                logger.info(f"‚úÖ HTML geladen: {len(html_content)} Zeichen")
                
                # Rohe Produktdaten extrahieren
                raw_products = await crawler._extract_raw_products(html_content)
                logger.info(f"üì¶ Rohe Produktelemente: {len(raw_products)}")
                
                # Erste 5 Elemente anzeigen
                for i, raw_product in enumerate(raw_products[:5], 1):
                    logger.info(f"\n--- Rohprodukt {i} ---")
                    logger.info(f"Text: {raw_product.text_content[:200]}...")
                    logger.info(f"Preise: {raw_product.price_candidates}")
                    logger.info(f"Namen: {raw_product.name_candidates[:3]}")
            else:
                logger.error("‚ùå Kein HTML-Inhalt erhalten")
        
    except Exception as e:
        logger.error(f"‚ùå Fehler bei roher Extraktion: {e}", exc_info=True)

if __name__ == "__main__":
    # Teste zuerst rohe Extraktion
    asyncio.run(test_raw_extraction())
    
    print("\n" + "="*50 + "\n")
    
    # Dann vollst√§ndigen intelligenten Test
    asyncio.run(test_intelligent_lidl_crawler()) 